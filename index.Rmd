---
title: "R로 웹 데이터를 가져오는 4가지 방법(은 크롤링)"
author: "박찬엽"
date: "2017년 10월 18일"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "custom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = T, fig.height = 5)
```


class: center, middle, title-slide

## R로 웹 데이터를 가져오는 4가지 방법(은 크롤링)

### <https://mrchypark.github.io/getWebR>

### 박찬엽

### 2017년 10월 18일

---

## 발표자소개
.center[
  #### 질문 / 상담 / 잡담 대환영!
]

.pull-left[
  .pull-right[
<br>
<br>
    ![](https://avatars2.githubusercontent.com/u/6179259?v=4&s=460)
  ]
]
.pull-right[
### 박찬엽    
- 서울도시가스 선행연구팀 연구원
- 패스트 캠퍼스 [중급R프로그래밍](http://www.fastcampus.co.kr/data_camp_dabrp/) 강의
- R 네이버 뉴스 크롤러 [N2H4](https://github.com/forkonlp/N2H4) 관리자
- .yellow[**KAKAO**]@[알코홀릭](http://pf.kakao.com/_RXANd) R 질문방 운영
- .blue[**FACEBOOK**]@[mrchypark](https://www.facebook.com/mrchypark)
- .gray[**GITHUB**]@[mrchypark](https://github.com/mrchypark)
]


---

class: center, middle, title-slide

## R로 웹 데이터를 가져오는 4가지 방법

---
class: center, middle, title-slide

## 웹에 있는 데이터를 가져오는 단계

### 요청 - 추출 - 저장 
### 반복 - 예외처리 - 최적화

---

## 관련 R 패키지 및 함수

#### - 요청 : curl, httr, rvest, RSelenium
#### - 정리 : 정규표현식, jsonlite, rvest
#### - 저장 : write.*()
#### - 반복 : for, parallel
#### - 예외처리 : try, if
#### - 최적화 : profvis, microbenchmark

---

## 관련 R 패키지 및 함수

#### **- 요청 : curl, httr, rvest, RSelenium**
#### **- 정리 : 정규표현식, jsonlite, rvest**
#### - .gray[저장 : write.*()]
#### - .gray[반복 : for, parallel]
#### - .gray[예외처리 : try, if]
#### - .gray[최적화 : profvis, microbenchmark]

---

class: center, middle, title-slide

## 오늘 이야기 할 것

### 요청(4가지)과 정리
### .gray[메인과 에피타이저]

---

class: center, middle, title-slide

## 그럼 에피타이저 먼저!

---

## 서버가 하는 것
.pull-left[
외부에서 요청하면 규칙대로 정보를 제공하는 것
]
.pull-right[
![](https://pbs.twimg.com/profile_images/581161893219323904/eGnWc30X.png)
]
---

## 브라우저가 하는 것

.pull-left[
서버가 주는 것들을 사용자에게 보여주는 것
]
.pull-right[
![](https://cdn.dribbble.com/users/107490/screenshots/2384364/icon-cloud-06_1x.png)
]
---

## 웹 서버가 우리에게 주는 것

text(html, css, js, etc), image. 브라우저가 약속된 모양으로 우리에게 보여줌.

.pull-center[.set[
![](https://qph.ec.quoracdn.net/main-qimg-1f99b9ce08edd2309efff97b710ffcbe)
]]

---

## 실제로 브라우저가 받는 파일들

.pull-center[.half[
![](https://raw.githubusercontent.com/mrchypark/getWebR/master/img/source.png)
]]

---

class: center, middle, title-slide

## * 그럼 web api는 뭔가?

web으로 제공되는 Application Programming Interface

함수인데 외부 서버에서 동작하여 웹 기술로 결과를 받는 것

---

## 우리가 필요한 것

text(html) 중 일부만(ex>제목)

![](https://raw.githubusercontent.com/mrchypark/getWebR/master/img/title.png)

---

class: center, middle, title-slide


### 그럼 이제 정리(에피타이저)를 설명

#### .blue[html 문서안에 글자 중 필요한 것만 가져오기]

---

class: center, middle, title-slide

#### 1번 글자를 다루는 강력한 방법 : 정규표현식 하지만 어려움    

### 2번 xml의 node를 다루는 패키지 : rvest

---

class: center, middle, title-slide

정규표현식은 [검색](https://www.google.co.kr/search?q=%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D&oq=%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D&aqs=chrome..69i57j69i61.2391j0j7&sourceid=chrome&ie=UTF-8)해보세요.
r에서는 [stringr](https://github.com/tidyverse/stringr) 이라는 서포트 패키지가 있음.

---

class: center, middle, title-slide

## [rvest](https://github.com/hadley/rvest)

### node, attr, text만 기억하면 됨.

---

## node란

html에서 tag라고 불리는 것.
.pull-center[.ori[
![](https://lh3.googleusercontent.com/SSAbYW6kAM728XuKv3PK5Uhgva0ueIBDnoGhPkou6lp9QYgDVwRFivfQNgORT8FT5js4gBFezjSvZlqujcbWup6yXvRTkEOkMotawSPcaOpc9dQvyVP05ODEFw)
]]
---

## 그럼 html 이란

[xml](https://ko.wikipedia.org/wiki/XML)양식으로 작성된 웹 브라우저들이 이해하는 표준 문서

.pull-center[.ori[
![](https://lh3.googleusercontent.com/az75sycVUFHD0aIKUmCZrs_Nf3-LCxiHSsYUZ_z5umiHK3XX77f1A6vCCD7YZYQNOAploEFjMYcu9x-DxRe5JdqZGFsnA3FhCvO3pRNBsK5M50RgzKd0hrx2gg)
]]

---

## attr 이란

attr은 attribute의 줄임으로 아래 예시로 tag의 attr1은 example1 임

```{}
<tag attr1="example1" attr2="example2"> 안녕하세요 </tag>
```

---

#### 원하는 글자가 있는 노드를 지정하기 위해서

[css 선택자](http://www.nextree.co.kr/p8468/)를 공부해야 함.

--

#### css 선택자가 동작하는 방식

1. tag 이름
2. tag의 id 속성
3. tag의 class 속성
4. tag의 custom 속성

--

#### css 선택자로 node를 선택하기 위해서

1. `tag`
1. `#id`
1. `.class`
1. `[attr="val"]`
1. `tag#id`
1. `tag.class`
1. `tag[attr="val"]`

---

## text 이란

text은 시작 태그와 종료 태그 사이에 있는 글자로, 아래 예시 기준 "안녕하세요" 를 뜻함

```{}
<tag attr1="example1" attr2="example2"> 안녕하세요 </tag>
```

---

## rvest의 동작 순서(text 가져오기)

1. html 문서 데이터 가져오기
1. 필요한 노드 선택하기
1. 노드내에 text를 가져오기


### rvest 함수

```{}
read_html(url)
read_html(url) %>% html_nodes("tag.class")
read_html(url) %>% html_nodes("tag.class") %>% html_text
```

---

## rvest의 동작 순서(attr 가져오기)

1. html 문서 데이터 가져오기
1. 필요한 노드 선택하기
1. 노드내에 attr 중에 "attr1"값을 가져오기


### rvest 함수

```{}
read_html(url)
read_html(url) %>% html_nodes("tag.class")
read_html(url) %>% html_nodes("tag.class") %>% html_attr("attr1")
```

---

## 예시

```{r}
library(rvest)
url<-"http://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=102&sid2=250&oid=025&aid=0002763120"
(nv<-read_html(url))
(nvns<-html_nodes(nv, "h3#articleTitle"))
```
.pull-left[
```{r}
(title<-html_text(nvns))
```
]
.pull-right[
```{r}
(class<-html_attr(nvns, "class"))
```
]
---

class: center, middle, title-slide

rvest는 html 문서로 되어 있는 웹에서의 텍스트 데이터를 가져와서 처리하는 패키지

---

class: center, middle, title-slide

## 이제 메인! 요청하기
### (read_html이 방법 1 ㄷㄷㄷ)

---

class: center, middle, title-slide

### 그래서 우리가 알아야 할 것

## GET과 POST

---

class: center, middle, title-slide

방금 read_html 함수는 GET 방식으로 서버에 요청하여 html 문서를 받은 것.

---

class: center, middle, title-slide

http 표준 요청을 수행해 주는 [httr](https://github.com/r-lib/httr) 패키지

---

## GET 요청

read_html(url) == content(GET(url)) 인걸로 GET 요청으로 html 문서를 가져올 때는 read_html()함수가 함께 처리해줌.

```{r}
library(httr)
library(rvest)

url<-"http://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=437&aid=0000165410"
dat<-GET(url)
content(dat)

read_html(url)
```

---

class: center, middle, title-slide

## 왜 GET 함수를 써야 하는가

header, cookie 등 다양한 옵션을 사용할 수 있음.    

ex> 크롤러가 아니라고 속여야 한다던가....

---

class: center, middle, title-slide

### 그럼 POST 란?

---

## POST 란

body에 사용자가 필요한 값을 추가해서 요청을 할 수 있는 방법

---

## 사용할 api

[한글 띄어쓰기 api](http://freesearch.pe.kr/archives/4647)

띄어쓰기가 불문명한 텍스트를 전달하면 맞는 띄어쓰기 결과를 돌려줌.

---

## 실행

```{r}
library(httr)

body<-list(sent="아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
res<-PUT(url='http://35.201.156.140:8080/spacing', body=body)

content(res)$sent
```

---

## body 란

list() 자료형으로 되어 있고 이름이 있는 데이터로 만든 요청에 추가할 수 있는 값

```{r}
body<-list(sent="아래와같은방식으로API를사용할수있으며,호출건수에대해서별도의제한은없으나,1회 호출에200글자로글자수를제한하고있다.")
body
```


---

## 여긴 PUT 이라고 되어 있는데?

PUT은 POST와 매우 유사한 요청 방식으로 서버에서 요구하는 방식을 지켜줘야함. 예시로 PUT을 사용했지만, 다른 POST가 필요한 곳에서는 POST 명령으로 작성하면 됨. 서비스 제공자가 설명서를 작성하게 되어있음.

```{r}
(res<-PUT(url='http://35.201.156.140:8080/spacing', body=body))
```

---

## api 명세 예시

![](https://raw.githubusercontent.com/mrchypark/getWebR/master/img/api.png)

---

## content() 함수

httr 패키지의 요청들은 read_html() 함수와 달리 header 나 cookie 등의 모든 정보를 다 확인할 수 있음. 그래서 응답으로 서버가 데이터로써 준 내용을 확인하기 위해서 content() 함수를 제공함.

```{r}
content(res)
```

---

class: center, middle, title-slide

여기까지가 http 요청을 따라하는 httr 패키지(방법 2)

---

그럼 웹 서비스 2가지에 대응할 수 있게 되었음.

하나는 정적 웹 서비스, 다른 하나는 web api.
이제 javascript를 이용한 동적 웹 서비스를 가져오는 방법이 필요

js란 브라우저에서 동작하는 개발 언어!

대표적인 사용처는 html 수정(정확하게 맞는 표현은 아니지만...)

정적 vs 동적




그래서 동적 부분의 수정된 html을 가져오려면 브라우저가 필요함

사용할 수 있는 대표적인 패키지 RSelenium

Selenium은 코드로 브라우저를 컨트롤하는 패키지.
그래서 브라우저를 움직일 수 있다!

단점 > 느림 그래서!

+ phantomjs

phantomjs는 headless 브라우저임
headless란 사람이 보는 부분이 없는 것

최근 chrome도 headless를 자체적으로 지원하기 시작함
아직 R 패키지로 나오지는 않았지만 조만간 지원할 듯

RSelenium이란 브라우저를 컨트롤하는 패키지(방법 3)


마지막으로...
+고급

크롬 개발자 도구를 이용하면 js가 가져오는 api를 찾아서
더 빠르게 정보를 가져올 수 있음

---

```{r}
url<-"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=news&templateId=view_society&pool=cbox5&_callback=jQuery1707377572341505474_1508264183038&lang=ko&country=&objectId=news437%2C0000165410&categoryId=&pageSize=10&indexSize=10&groupId=&listType=OBJECT&page=1&sort=new&includeAllStatus=true&_=1508264264524"

con <- httr::GET(url)
tt <- httr::content(con, "text")
```

---

```{r}
url<-"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=news&templateId=view_society&pool=cbox5&_callback=jQuery1707377572341505474_1508264183038&lang=ko&country=&objectId=news437%2C0000165410&categoryId=&pageSize=10&indexSize=10&groupId=&listType=OBJECT&page=1&sort=new&includeAllStatus=true&_=1508264264524"
ref<-"http://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=437&aid=0000165410"
con <- httr::GET(url,
                 httr::add_headers(Referer = ref))
tt <- httr::content(con, "text")
```

---

```{r eval=FALSE}
url<-"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=news&templateId=view_society&pool=cbox5&_callback=jQuery1707377572341505474_1508264183038&lang=ko&country=&objectId=news437%2C0000165410&categoryId=&pageSize=10&indexSize=10&groupId=&listType=OBJECT&page=1&sort=new&includeAllStatus=true&_=1508264264524"
ref<-"http://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=437&aid=0000165410"
con <- httr::GET(url,
                 httr::add_headers(Referer = ref))
tt <- httr::content(con, "text")
jsonlite::fromJSON(tt)
```

---

```{r}
url<-"https://apis.naver.com/commentBox/cbox/web_naver_list_jsonp.json?ticket=news&templateId=view_society&pool=cbox5&_callback=jQuery1707377572341505474_1508264183038&lang=ko&country=&objectId=news437%2C0000165410&categoryId=&pageSize=10&indexSize=10&groupId=&listType=OBJECT&page=1&sort=new&includeAllStatus=true&_=1508264264524"
ref<-"http://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=437&aid=0000165410"
con <- httr::GET(url,
                 httr::add_headers(Referer = ref))
tt <- httr::content(con, "text")

tt <- gsub("(;|\n|_callback|jQuery1707377572341505474_1508264183038)", "", tt)
tt <- gsub("\\(", "[", tt)
tt <- gsub("\\)", "]", tt)

data <- jsonlite::fromJSON(tt)
data$result$commentList[[1]]$contents
```

---

class: center, middle, title-slide

# 끝!
### <https://mrchypark.github.io/getWebR>
